{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "169c79b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #импортируем библиотеку для работы с данными в виде таблиц - `pandas`, и задаем ей сокращенное название `pd`\n",
    "import numpy as np #импортируем библиотеку для работы с числами и массивами - `numpy`, и задаем ей сокращенное название `np`\n",
    "from tqdm.notebook import tqdm #импортируем модуль `tqdm` из библиотеки `tqdm`, который позволяет отслеживать прогресс выполнения длительных операций, и конкретно используем здесь версию `tqdm` для использования в блокнотах `notebook`.\n",
    "\n",
    "import torch #импортируем библиотеку для работы с нейронными сетями `PyTorch`\n",
    "import torch.nn as nn #импортируем модуль `nn` из библиотеки `PyTorch`, который содержит функции для определения нейронных сетей.\n",
    "from torch.utils.data import Dataset, DataLoader #импортируем классы `Dataset` и `DataLoader` из библиотеки `PyTorch`, которые позволяют загружать данные в нейронную сеть и обрабатывать их в виде батчей.\n",
    "import pytorch_lightning as pl #импортируем библиотеку `PyTorch Lightning`, которая предоставляет удобный интерфейс для обучения моделей на `PyTorch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4c613391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27753444, 4)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pd.read_csv('ratings.csv') # данная строка загружает данные из файла 'ratings.csv' и сохраняет их в переменную `ratings` в виде таблицы (DataFrame) с помощью функции `read_csv()` из библиотеки Pandas. Файл должен находиться в том же каталоге, что и файл с данным кодом.\n",
    "ratings.head() #выводит первые 5 строк таблицы `ratings` с помощью функции `head()` из библиотеки Pandas.\n",
    "ratings.shape #выводит размерности таблицы `ratings` в виде кортежа (количество строк, количество столбцов) с помощью атрибута `shape` у переменной `ratings`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4c25f8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 829177 rows of data from 8496 users\n"
     ]
    }
   ],
   "source": [
    "#Первая строка кода генерирует случайную выборку пользователей, которые сделали оценки. В методе numpy.random.choice первым\n",
    "#параметром передается уникальный список userId из DataFrame ratings, а вторым параметром передается количество \n",
    "#пользователей, которые будут выбраны (3% от общего числа пользователей в данном случае), и replace=False означает, что \n",
    "#каждый выбранный пользователь будет уникальным\n",
    "rand_userIds = np.random.choice(ratings['userId'].unique(), \n",
    "                                size=int(len(ratings['userId'].unique())*0.03), \n",
    "                                replace=False)\n",
    "#фильтрация DataFrame ratings по выбранным пользователей. Метод loc позволяет отбирать строки по условию, используя\n",
    "#индексацию по меткам. Метод isin получает DataFrame рейтингов с строками, где столбец userId имеет значение, принадлежащее \n",
    "#выборке пользователей.\n",
    "ratings = ratings.loc[ratings['userId'].isin(rand_userIds)]\n",
    "#выводит на экран количество строк данных и количество выбранных пользователей с помощью метода format. Здесь {} заменяются \n",
    "#на len(ratings) и len(rand_userIds) соответственно.\n",
    "print('There are {} rows of data from {} users'.format(len(ratings), len(rand_userIds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9b155314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(829177, 4)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e7365f",
   "metadata": {},
   "source": [
    "### Используя столбец timestamp, мы реализуем нашу стратегию разделения обучения и тестирования, используя методологию \"оставить по одному\". Для каждого пользователя самый последний обзор используется в качестве тестового набора (т.е. один из них исключается), в то время как остальные будут использоваться в качестве обучающих данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9ece9971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1494         1.0\n",
       "1495         2.0\n",
       "2088        11.0\n",
       "2089        15.0\n",
       "2090         4.0\n",
       "            ... \n",
       "27752566    12.0\n",
       "27752567     1.0\n",
       "27752568     2.0\n",
       "27752569    29.0\n",
       "27752570    31.0\n",
       "Name: timestamp, Length: 829177, dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Приведенный ниже код разделит наш набор данных о рейтингах на обучающий и тестовый наборы, используя методологию \"оставить \n",
    "#все как есть\".\n",
    "ratings.groupby(['userId'])['timestamp'].rank(method='first', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fe184c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(829177, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>rank_latest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1494</th>\n",
       "      <td>17</td>\n",
       "      <td>32</td>\n",
       "      <td>3.0</td>\n",
       "      <td>867664799</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>17</td>\n",
       "      <td>780</td>\n",
       "      <td>5.0</td>\n",
       "      <td>867664799</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2088</th>\n",
       "      <td>30</td>\n",
       "      <td>52</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1182961438</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2089</th>\n",
       "      <td>30</td>\n",
       "      <td>903</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1182961417</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2090</th>\n",
       "      <td>30</td>\n",
       "      <td>910</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1182961465</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      userId  movieId  rating   timestamp  rank_latest\n",
       "1494      17       32     3.0   867664799          1.0\n",
       "1495      17      780     5.0   867664799          2.0\n",
       "2088      30       52     3.5  1182961438         11.0\n",
       "2089      30      903     5.0  1182961417         15.0\n",
       "2090      30      910     3.5  1182961465          4.0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создается новый столбец 'rank_latest', который содержит ранг пользователя (userId) по времени (timestamp). \n",
    "#Дополнительно используется метод 'rank', который учитывает порядок появления записей (method='first') и сортирует в \n",
    "#порядке убывания(ascending=False).\n",
    "ratings['rank_latest'] = ratings.groupby(['userId'])['timestamp'] \\\n",
    "                                .rank(method='first', ascending=False)\n",
    "\n",
    "train_ratings = ratings[ratings['rank_latest'] != 1] #Создаются обучающие данные (train_ratings), содержащие все записи, \n",
    "#кроме тех, где rank_latest равно 1 (знак, что это последняя оценка пользователя).\n",
    "test_ratings = ratings[ratings['rank_latest'] == 1] #Создаются тестовые данные (test_ratings), содержащие записи последней\n",
    "#оценки пользователей.\n",
    "print(ratings.shape)\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8f714e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns that we no longer need\n",
    "train_ratings = train_ratings[['userId', 'movieId', 'rating']]\n",
    "test_ratings = test_ratings[['userId', 'movieId', 'rating']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfd028a",
   "metadata": {},
   "source": [
    "### Чтобы преобразовать этот набор данных в набор данных неявной обратной связи, мы просто бинаризуем оценки таким образом, чтобы они были равны \"1\" (т.е. положительный класс). Значение \"1\" означает, что пользователь взаимодействовал с элементом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "641c9804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(820681, 3)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ratings.loc[:, 'rating'] = 1 #Этот код устанавливает значение 1 для всех элементов столбца \"rating\" в датафрейме \n",
    "#train_ratings. В данном случае \":\" означает, что нужно выбрать все строки в датафрейме, а \"loc\" используется для индексации\n",
    "#по меткам (в данном случае мы используем метки строк \":\", а столбца \"rating\"). Таким образом, мы заменяем рейтинги всех \n",
    "#фильмов в датафрейме на значение 1 (например, если это датафрейм для задачи бинарной классификации, где 1 обозначает \n",
    "#положительный класс, а 0 - отрицательный класс).\n",
    "\n",
    "train_ratings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d68f94",
   "metadata": {},
   "source": [
    "### После того, как мы бинаризовали наш набор данных, мы обнаружили, что все образцы находятся в классе positive. Для того, чтобы наши модели были обучены правильно, нам также нужны отрицательные образцы, которые помогут указать, какие фильмы неинтересны пользователю. Хотя мы предположили, что отрицательные образцы - это те, которые пользователь не смотрел, это предположение может оказаться неверным. Однако, на практике это довольно хорошо работает.Наши 4 отрицательных выборки для каждого образца данных созданы для того, чтобы соотношение отрицательных и положительных образцов в нашем наборе данных было 4:1. Этот произвольный выбор соотношения был сделан, потому что он работает хорошо."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "96c4219c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Данный код извлекает все уникальные идентификаторы фильмов из столбца \"movieId\" в таблице \"ratings\" и сохраняет их в \n",
    "#массив \"all_movieIds\".\n",
    "all_movieIds = ratings['movieId'].unique()\n",
    "\n",
    "\n",
    "users, items, labels = [], [], [] # Этот код создает три пустых списка. \n",
    "\n",
    "user_item_set = set(zip(train_ratings['userId'], train_ratings['movieId'])) #Этот код создает множество (set) под названием\n",
    "#\"user_item_set\", которое содержит кортежи (tuples) - пары значений из двух столбцов \"userId\" и \"movieId\" из DataFrame \n",
    "#\"train_ratings\". Функция \"zip()\" создает последовательность кортежей соответствующих элементов из каждого переданного \n",
    "#списка (в данном случае два списка - \"userId\" и \"movieId\"). Кортежи добавляются в множество, которое удаляет любые \n",
    "#дублирующиеся кортежи. Таким образом, на выходе получаем множество всех уникальных комбинаций \"userId\" и \"movieId\" из \n",
    "#\"train_ratings\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "32ad72f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3887b98d0bd3412cb71be237c6ac173a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/820681 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Этот код используется для создания тренировочных датасетов в задаче рекомендации фильмов. Он проходится по каждому \n",
    "#пользователю и их взаимодействию с фильмами из датасета, затем генерирует отрицательные примеры для каждого пользователя. \n",
    "num_negatives = 4 #количество выбранных отрицательных примеров для каждого положительного примера.\n",
    "\n",
    "for (u, i) in tqdm(user_item_set): #цикл перебирает каждую пару пользователь-фильм в датасете, используя библиотеку \n",
    "    #tqdm для отслеживания прогресса перебора. \n",
    "    users.append(u) #добавляет пользователя в список пользователей.\n",
    "    items.append(i) #добавляет взаимодействующий фильм в список фильмов. \n",
    "    labels.append(1) #добавляет метку \"1\", чтобы указать, что пользователь взаимодействовал с этим фильмом, и это \n",
    "    #положительный пример для обучения. \n",
    "    for _ in range(num_negatives):#генерирует отрицательные примеры для каждого пользователя. \n",
    "        negative_item = np.random.choice(all_movieIds) #случайно выбирает фильм из всех фильмов в датасете. \n",
    "        while (u, negative_item) in user_item_set:# проверяет, что пользователь не взаимодействовал с этим фильмом до этого.\n",
    "            #Если да, то случайным образом выбирается другой фильм до тех пор, пока не будет найден фильм, с которым \n",
    "            #пользователь еще не взаимодействовал.\n",
    "            negative_item = np.random.choice(all_movieIds)\n",
    "        users.append(u)#добавляет пользователя в список пользователей для этого отрицательного примера. \n",
    "        items.append(negative_item)#добавляет отрицательный фильм в список фильмов для этого примера. \n",
    "        labels.append(0) #добавляет метку \"0\" для этого отрицательного примера."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3271b4",
   "metadata": {},
   "source": [
    "### Приведенный ниже класс просто инкапсулирует код, который мы написали выше, в класс набора данных PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "728589cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Этот код представляет собой класс Dataset PyTorch для обучения модели рекомендации кинопроизведений MovieLens.\n",
    "class MovieLensTrainDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, ratings, all_movieIds): #определение конструктора класса с аргументами данных о рейтингах и списке id всех фильмов.\n",
    "        self.users, self.items, self.labels = self.get_dataset(ratings, all_movieIds) #инициализация пользователей, фильмов и меток их рейтинга через вызов метода get_dataset.\n",
    "\n",
    "    def __len__(self): #переопределение метода len()\n",
    "        return len(self.users) #возвращает длину списка пользователей.\n",
    "  \n",
    "    def __getitem__(self, idx):# переопределение метода getitem().\n",
    "        return self.users[idx], self.items[idx], self.labels[idx]#возвращает определенные пользователем, фильм и метку рейтинга для заданного индекса.\n",
    "\n",
    "    def get_dataset(self, ratings, all_movieIds):#определение метода get_dataset() с аргументами оценками и списком id фильмов.\n",
    "        users, items, labels = [], [], [] #инициализация пустых списков пользователей, фильмов и меток рейтинга.\n",
    "        user_item_set = set(zip(ratings['userId'], ratings['movieId']))# создание множества пар пользователя-фильма на основе данных оценок\n",
    "\n",
    "        num_negatives = 4 #количество выбранных отрицательных примеров для каждого положительного примера.\n",
    "        for u, i in user_item_set: #раскрытие множества пар на пользователей и фильмы.\n",
    "            users.append(u) #добавление пользователя в список пользователей.\n",
    "            items.append(i) #добавление фильма в список фильмов.\n",
    "            labels.append(1) #добавление метки рейтинга в список меток рейтинга.\n",
    "            for _ in range(num_negatives): # запускается цикл выбора случайных отрицательных примеров для каждого положительного примера\n",
    "                negative_item = np.random.choice(all_movieIds)#выбор случайного фильма из списка всех фильмов.\n",
    "                while (u, negative_item) in user_item_set:#проверка наличия уже оцененного или случайно выбранного пары пользователь-фильм.\n",
    "                    negative_item = np.random.choice(all_movieIds)#выбор случайного фильма из списка всех фильмов.\n",
    "                users.append(u)#добавление пользователя в список пользователей.\n",
    "                items.append(negative_item)#добавление отрицательного примера в список фильмов.\n",
    "                labels.append(0)#добавление метки рейтинга 0 для отрицательного примера.\n",
    "\n",
    "        return torch.tensor(users), torch.tensor(items), torch.tensor(labels) #возврат кортежа, состоящего из списков пользователей, фильмов и меток рейтинга, преобразованных в тензоры PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadfc357",
   "metadata": {},
   "source": [
    "### Мы создали модель, которая помогает нам понять, что пользователи любят смотреть в кино - боевики или романтические фильмы. Называется она Нейронная коллаборативная фильтрация или NCF. Мы расположили пользователей в двумерном пространстве, чтобы легче понимать их предпочтения. А для фильмов мы использовали отдельный слой встраивания элементов. В итоге мы можем идентифицировать, какие фильмы нравятся похожим пользователям, и на основе этого сделать рекомендации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3c91bf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCF(pl.LightningModule): #Создается класс `NCF`, который наследует функционал от `pl.LightningModule`.\n",
    "    def __init__(self, num_users, num_items, ratings, all_movieIds): #Описывается метод `init`, который задает начальные параметры модели, такие как число пользователей (`num_users`), число элементов (`num_items`), массив оценок (`ratings`) и все идентификаторы фильмов (`all_movieIds`). \n",
    "        super().__init__()\n",
    "        #Создаются слои `Embedding` для пользователей и элементов с разными размерностями параметров (`num_embeddings` и `embedding_dim`).\n",
    "        self.user_embedding = nn.Embedding(num_embeddings=num_users, embedding_dim=8)\n",
    "        self.item_embedding = nn.Embedding(num_embeddings=num_items, embedding_dim=8)\n",
    "        #Создаются слои `Linear` для прямого распространения данных (`in_features` и `out_features`).\n",
    "        self.fc1 = nn.Linear(in_features=16, out_features=64)\n",
    "        self.fc2 = nn.Linear(in_features=64, out_features=32)\n",
    "        self.output = nn.Linear(in_features=32, out_features=1)\n",
    "        self.ratings = ratings\n",
    "        self.all_movieIds = all_movieIds\n",
    "    #Создается функция `forward`, которая описывает, как данные проходят через слои модели: сначала попадают на вход в `Embedding`, затем образуют единый вектор и проходят через все слои `Linear` с последующей применением функций активации. Наконец, для получения бинарной классификации применяется `nn.Sigmoid()`.\n",
    "    def forward(self, user_input, item_input):\n",
    "        user_embedded = self.user_embedding(user_input)\n",
    "        item_embedded = self.item_embedding(item_input)\n",
    "        \n",
    "        vector = torch.cat([user_embedded, item_embedded], dim=-1)\n",
    "        \n",
    "        vector = nn.ReLU()(self.fc1(vector))\n",
    "        vector = nn.ReLU()(self.fc2(vector))\n",
    "        \n",
    "        pred = nn.Sigmoid()(self.output(vector))\n",
    "\n",
    "        return pred\n",
    "    #Создается метод `training_step`, который используется для вычисления ошибки при обучении. \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        user_input, item_input, labels = batch\n",
    "        predicted_labels = self(user_input, item_input)\n",
    "        loss = nn.BCELoss()(predicted_labels, labels.view(-1, 1).float())\n",
    "        return loss\n",
    "    #Создается метод `configure_optimizers`, который возвращает оптимизатор - Adam.\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters())\n",
    "    #Создается метод `train_dataloader`, который используется для загрузки обучающих данных. Функция `DataLoader` загружает обучающие данные из `MovieLensTrainDataset` в пакетах (`batch_size=512`). `num_workers=0` означает, что данные загружаются синхронно (без использования нескольких процессов).\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(MovieLensTrainDataset(self.ratings, self.all_movieIds),\n",
    "                          batch_size=512, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1aea449",
   "metadata": {},
   "source": [
    "### Мы создаем экземпляр модели NCF, используя класс, который мы определили выше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7baa92fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = ratings['userId'].max()+1 #Эта строка кода создает переменную num_users, которая равна максимальному значению идентификатора пользователя в столбце \"userId\" из датафрейма ratings, увеличенному на единицу. Это нужно для того, чтобы определить количество пользователей, на которых будет обучаться модель.\n",
    "num_items = ratings['movieId'].max()+1 #Эта строка кода создает переменную num_items, которая равна максимальному значению идентификатора фильма в столбце \"movieId\" из датафрейма ratings, увеличенному на единицу. Это нужно для того, чтобы определить количество фильмов, на которых будет обучаться модель.\n",
    "\n",
    "all_movieIds = ratings['movieId'].unique() #Эта строка кода создает переменную all_movieIds, которая содержит уникальные идентификаторы фильмов из столбца \"movieId\" датафрейма ratings. Это нужно для того, чтобы передать эти значения в модель и использовать их при генерации рекомендаций.\n",
    "model = NCF(num_users, num_items, train_ratings, all_movieIds) #Эта строка кода создает экземпляр класса NCF и передает в него параметры: num_users - количество пользователей, num_items - количество фильмов, train_ratings - обучающий датафрейм, all_movieIds - список уникальных идентификаторов фильмов. Эта модель будет использоваться для генерации рекомендаций на основе данных из train_ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24263ef",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7e1b3c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name           | Type      | Params\n",
      "---------------------------------------------\n",
      "0 | user_embedding | Embedding | 2.3 M \n",
      "1 | item_embedding | Embedding | 1.5 M \n",
      "2 | fc1            | Linear    | 1.1 K \n",
      "3 | fc2            | Linear    | 2.1 K \n",
      "4 | output         | Linear    | 33    \n",
      "---------------------------------------------\n",
      "3.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "3.8 M     Total params\n",
      "15.274    Total estimated model params size (MB)\n",
      "C:\\Users\\Vlaso\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f080115eb8c24be89dbc5296a3f1fcc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3h 12min 1s\n",
      "Wall time: 1h 5min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time #это функция в Jupyter Notebook, которая позволяет измерить время выполнения кода в ячейках.\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=5) #это создание объекта Trainer из PyTorch Lightning с параметром max_epochs, указывающим количество эпох, которые будут обучены.\n",
    "\n",
    "trainer.fit(model) #это запуск тренировки модели с использованием созданного объекта Trainer и передача ему созданной ранее модели. Во время обучения модели Trainer будет обращаться к методам модели для получения и обновления ее параметров в каждую эпоху."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb15be7",
   "metadata": {},
   "source": [
    "### Нам не нужно, чтобы пользователь кликал на каждом элементе списка рекомендаций. Чтобы сделать систему удобнее для пользователя, достаточно, чтобы он кликнул хотя бы на одном элементе из списка. Наше исследование показало, что если мы предлагаем пользователю 10 товаров, то, если выбранный им товар окажется в топ-10, мы сможем считать нашу систему успешной. Мы провели эксперимент, где выбрали случайные 99 товаров, с которыми пользователь не взаимодействовал, и добавили к ним один тестовый товар. Модель предсказала вероятности для каждого из этих 100 товаров, и мы выбрали 10 наиболее вероятных. Если тестовый товар был среди этих 10, мы считали это попаданием. Мы проверили все товары для всех пользователей, и получили среднее количество попаданий. Эта оценка называется коэффициент попадания при 10 и помогает оценить эффективность нашей системы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8fb33c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e1ab42673754edba8cd85597193a249",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8496 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Hit Ratio @ 10 is 0.78\n"
     ]
    }
   ],
   "source": [
    "#Создаем множество из кортежей (userId, movieId) для тестовых данных\n",
    "test_user_item_set = set(zip(test_ratings['userId'], test_ratings['movieId']))\n",
    "\n",
    "#Создаем словарь: для каждого пользователя описываем фильмы, с которыми он взаимодействовал\n",
    "user_interacted_items = ratings.groupby('userId')['movieId'].apply(list).to_dict()\n",
    "\n",
    "hits = [] #cоздаем пустой список для хранения результатов\n",
    "for (u,i) in tqdm(test_user_item_set): # Итерируемся по всем юзерам и фильмам в тестовых данных, и для каждого из них строим рекомендации\n",
    "    # Получаем список фильмов, с которыми взаимодействовал данный пользователь\n",
    "    interacted_items = user_interacted_items[u]\n",
    "    # Получаем множество фильмов, с которыми не взаимодействовал данный пользователь\n",
    "    not_interacted_items = set(all_movieIds) - set(interacted_items)\n",
    "    # Случайным образом выбираем 99 фильмов, с которыми пользователь не взаимодействовал\n",
    "    selected_not_interacted = list(np.random.choice(list(not_interacted_items), 99))\n",
    "    # Формируем список фильмов, с которыми взаимодействовал пользователь и случайно выбранных фильмов\n",
    "    # Добавляем в список исходный фильм i, для которого будем строить рекомендации\n",
    "    test_items = selected_not_interacted + [i]\n",
    "    # Строим предсказания рейтингов фильмов\n",
    "    predicted_labels = np.squeeze(model(torch.tensor([u]*100), \n",
    "                                        torch.tensor(test_items)).detach().numpy())\n",
    "     # Отбираем топ-10 фильмов с наибольшими предсказанными рейтингами\n",
    "    top10_items = [test_items[i] for i in np.argsort(predicted_labels)[::-1][0:10].tolist()]\n",
    "    # Если исходный фильм i оказался в топ-10, добавляем 1 в список hits, т.е. рекомендация сработала\n",
    "    if i in top10_items:\n",
    "        hits.append(1)\n",
    "    # Если нет, то добавляем 0\n",
    "    else:\n",
    "        hits.append(0)\n",
    "# Выводим результат: среднее значение списка hits\n",
    "print(\"The TOP @ 10 is {:.2f}\".format(np.average(hits)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3806d2",
   "metadata": {},
   "source": [
    "### это означает, что 78% пользователей были рекомендованы фактические товары (из списка из 10 товаров), с которыми они в конечном итоге взаимодействовали."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff5b60c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
